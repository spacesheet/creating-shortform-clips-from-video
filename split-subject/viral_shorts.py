# -*- coding: utf-8 -*-

import os
import json
import subprocess
from datetime import timedelta
import whisper
from pathlib import Path
import xml.etree.ElementTree as ET
from xml.dom import minidom
import torch
import numpy as np
from sentence_transformers import SentenceTransformer
from sklearn.feature_extraction.text import TfidfVectorizer
from collections import Counter
import re

class TopicBasedShortCreator:
    def __init__(self, video_path, keywords=None, output_dir="shorts", similarity_threshold=0.7):
        self.video_path = video_path
        self.keywords = [k.lower() for k in keywords] if keywords else []
        self.output_dir = output_dir
        self.similarity_threshold = similarity_threshold
        self.transcription_file = "transcription.json"
        os.makedirs(output_dir, exist_ok=True)
        
        # ì˜ë¯¸ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
        print("ğŸ¤– ë¬¸ì¥ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì¤‘...")
        self.embedding_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
        
        # ë¹„ë””ì˜¤ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        self.video_info = self._get_video_info()
        
    def _get_video_info(self):
        """ffprobeë¡œ ë¹„ë””ì˜¤ ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""
        cmd = [
            'ffprobe',
            '-v', 'quiet',
            '-print_format', 'json',
            '-show_format',
            '-show_streams',
            self.video_path
        ]
        
        try:
            result = subprocess.run(cmd, capture_output=True, text=True, check=True)
            info = json.loads(result.stdout)
            
            video_stream = None
            for stream in info['streams']:
                if stream['codec_type'] == 'video':
                    video_stream = stream
                    break
            
            return {
                'duration': float(info['format']['duration']),
                'width': int(video_stream['width']),
                'height': int(video_stream['height'])
            }
        except Exception as e:
            print(f"âš ï¸  ë¹„ë””ì˜¤ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
            return {'duration': 0, 'width': 1920, 'height': 1080}
    
    def transcribe_video(self, force_new=False):
        """ì˜ìƒ ìŒì„± ì¸ì‹"""
        if os.path.exists(self.transcription_file) and not force_new:
            print("ğŸ“„ ê¸°ì¡´ ìë§‰ íŒŒì¼ ë¡œë“œ ì¤‘...")
            with open(self.transcription_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        
        print("ğŸ¤ ìŒì„± ì¸ì‹ ì‹œì‘... (ì‹œê°„ì´ ì¢€ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
        model = whisper.load_model("base", device="cpu")
        
        result = model.transcribe(
            self.video_path,
            language="ko",
            word_timestamps=True,
            verbose=False,
            fp16=False
        )
        
        with open(self.transcription_file, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… ìŒì„± ì¸ì‹ ì™„ë£Œ! (ì´ {len(result['segments'])}ê°œ êµ¬ê°„)")
        return result
    
    def find_topic_boundaries(self, segments, window_size=3):
        """ì˜ë¯¸ì  ìœ ì‚¬ë„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í™”ì œ ì „í™˜ì  ì°¾ê¸°"""
        print(f"\nğŸ” í™”ì œ ì „í™˜ì  ë¶„ì„ ì¤‘...")
        
        if len(segments) < 2:
            return [0, len(segments)]
        
        # ê° ì„¸ê·¸ë¨¼íŠ¸ì˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        texts = [seg['text'].strip() for seg in segments if seg['text'].strip()]
        
        if len(texts) < 2:
            return [0, len(segments)]
        
        # ë¬¸ì¥ ì„ë² ë”© ìƒì„±
        print("   ğŸ“Š ë¬¸ì¥ ì„ë² ë”© ìƒì„± ì¤‘...")
        embeddings = self.embedding_model.encode(texts, show_progress_bar=False)
        
        # ì—°ì†ëœ ì„¸ê·¸ë¨¼íŠ¸ ê°„ ìœ ì‚¬ë„ ê³„ì‚°
        similarities = []
        for i in range(len(embeddings) - 1):
            start_idx = max(0, i - window_size + 1)
            end_idx = min(len(embeddings), i + window_size + 1)
            
            window1 = np.mean(embeddings[start_idx:i+1], axis=0)
            window2 = np.mean(embeddings[i+1:end_idx], axis=0)
            
            similarity = np.dot(window1, window2) / (
                np.linalg.norm(window1) * np.linalg.norm(window2)
            )
            similarities.append(similarity)
        
        # ìœ ì‚¬ë„ê°€ ë‚®ì€ ì§€ì  = í™”ì œ ì „í™˜ì 
        boundaries = [0]
        for i, sim in enumerate(similarities):
            if sim < self.similarity_threshold:
                boundaries.append(i + 1)
                print(f"   âœ… í™”ì œ ì „í™˜ ê°ì§€: {i+1}ë²ˆì§¸ êµ¬ê°„ (ìœ ì‚¬ë„: {sim:.2f})")
        
        boundaries.append(len(segments))
        
        print(f"\nğŸ“Œ ì´ {len(boundaries)-1}ê°œì˜ í™”ì œ êµ¬ê°„ ë°œê²¬")
        return boundaries
    
    def extract_keywords(self, text, top_n=3):
        """í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        text = re.sub(r'[^\w\sê°€-í£]', ' ', text)
        
        stop_words = ['ì€', 'ëŠ”', 'ì´', 'ê°€', 'ì„', 'ë¥¼', 'ì—', 'ì˜', 'ì™€', 'ê³¼', 
                      'ë„', 'ìœ¼ë¡œ', 'ë¡œ', 'ì—ì„œ', 'í•˜ë‹¤', 'ìˆë‹¤', 'ë˜ë‹¤', 'ì´ë‹¤',
                      'ê·¸', 'ì €', 'ê²ƒ', 'ìˆ˜', 'ë“±', 'ë°', 'ì¢€', 'ë§‰', 'ì§„ì§œ', 'ë˜ê²Œ']
        
        words = text.split()
        words = [w for w in words if len(w) > 1 and w not in stop_words]
        
        if not words:
            return []
        
        word_counts = Counter(words)
        return [word for word, count in word_counts.most_common(top_n)]
    
    def contains_keywords(self, text, context_window=0):
        """í…ìŠ¤íŠ¸ì— ì§€ì •ëœ í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸"""
        if not self.keywords:
            return True, []
        
        text_lower = text.lower()
        matched = [kw for kw in self.keywords if kw in text_lower]
        return len(matched) > 0, matched
    
    def find_topic_segments(self, transcription, min_duration=15, max_duration=60, 
                           use_keyword_filter=True, context_segments=2):
        """
        í™”ì œ ë‹¨ìœ„ë¡œ êµ¬ê°„ ë¶„í• 
        
        Args:
            use_keyword_filter: í‚¤ì›Œë“œ í•„í„°ë§ ì‚¬ìš© ì—¬ë¶€
            context_segments: í‚¤ì›Œë“œ ë°œê²¬ ì‹œ ì•ë’¤ë¡œ í¬í•¨í•  êµ¬ê°„ ìˆ˜
        """
        segments = transcription['segments']
        
        # 1. í™”ì œ ê²½ê³„ ì°¾ê¸°
        boundaries = self.find_topic_boundaries(segments)
        
        # 2. ê° í™”ì œë¥¼ ìˆí¼ êµ¬ê°„ìœ¼ë¡œ ë³€í™˜
        topic_clips = []
        
        print(f"\nâœ‚ï¸  í™”ì œë³„ êµ¬ê°„ ìƒì„± ì¤‘...")
        if use_keyword_filter and self.keywords:
            print(f"ğŸ”‘ í‚¤ì›Œë“œ í•„í„°ë§: {', '.join(self.keywords[:10])}" + 
                  (f" ì™¸ {len(self.keywords)-10}ê°œ" if len(self.keywords) > 10 else ""))
        
        for i in range(len(boundaries) - 1):
            start_idx = boundaries[i]
            end_idx = boundaries[i + 1]
            
            if start_idx >= len(segments) or end_idx > len(segments):
                continue
            
            # í™”ì œ ë‚´ ëª¨ë“  ì„¸ê·¸ë¨¼íŠ¸ í•©ì¹˜ê¸°
            topic_segments = segments[start_idx:end_idx]
            
            if not topic_segments:
                continue
            
            # ì „ì²´ í…ìŠ¤íŠ¸
            full_text = ' '.join([s['text'] for s in topic_segments])
            
            # í‚¤ì›Œë“œ í•„í„°ë§
            if use_keyword_filter and self.keywords:
                has_keyword, matched_keywords = self.contains_keywords(full_text)
                
                if not has_keyword:
                    continue  # í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ ìŠ¤í‚µ
                
                # ì»¨í…ìŠ¤íŠ¸ í™•ì¥ (í‚¤ì›Œë“œ ì£¼ë³€ êµ¬ê°„ë„ í¬í•¨)
                extended_start_idx = max(0, start_idx - context_segments)
                extended_end_idx = min(len(segments), end_idx + context_segments)
                topic_segments = segments[extended_start_idx:extended_end_idx]
                full_text = ' '.join([s['text'] for s in topic_segments])
            else:
                matched_keywords = []
            
            start_time = topic_segments[0]['start']
            end_time = topic_segments[-1]['end']
            duration = end_time - start_time
            
            # í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ (ìë™ + ë§¤ì¹­ëœ í‚¤ì›Œë“œ)
            auto_keywords = self.extract_keywords(full_text, top_n=3)
            all_keywords = list(set(matched_keywords + auto_keywords))
            
            # ë„ˆë¬´ ì§§ê±°ë‚˜ ê¸´ êµ¬ê°„ ì¡°ì •
            if duration < min_duration:
                extend = (min_duration - duration) / 2
                start_time = max(0, start_time - extend)
                end_time = min(self.video_info['duration'], end_time + extend)
                duration = end_time - start_time
                
                topic_clips.append({
                    'topic_id': i + 1,
                    'keywords': all_keywords,
                    'matched_keywords': matched_keywords,
                    'text': full_text[:200],
                    'start': start_time,
                    'end': end_time,
                    'duration': duration
                })
                
            elif duration > max_duration:
                split_clips = self._split_long_topic(
                    topic_segments, 
                    max_duration, 
                    topic_id=i + 1,
                    keywords=all_keywords,
                    matched_keywords=matched_keywords
                )
                topic_clips.extend(split_clips)
                
            else:
                topic_clips.append({
                    'topic_id': i + 1,
                    'keywords': all_keywords,
                    'matched_keywords': matched_keywords,
                    'text': full_text[:200],
                    'start': start_time,
                    'end': end_time,
                    'duration': duration
                })
            
            # ì§„í–‰ìƒí™© ì¶œë ¥
            if len(topic_clips) <= 50 or len(topic_clips) % 10 == 0:
                print(f"   í™”ì œ {i+1}: {start_time:.1f}s ~ {end_time:.1f}s ({duration:.1f}ì´ˆ)")
                if matched_keywords:
                    print(f"      âœ… ë§¤ì¹­: {', '.join(matched_keywords[:3])}")
                elif all_keywords:
                    print(f"      í‚¤ì›Œë“œ: {', '.join(all_keywords[:3])}")
        
        print(f"\nğŸ¯ ì´ {len(topic_clips)}ê°œì˜ ìˆí¼ êµ¬ê°„ ìƒì„±")
        return topic_clips
    
    def _split_long_topic(self, segments, max_duration, topic_id=0, keywords=None, matched_keywords=None):
        """ê¸´ í™”ì œë¥¼ ì—¬ëŸ¬ ê°œì˜ ìˆí¼ìœ¼ë¡œ ë¶„í• """
        clips = []
        current_segments = []
        current_duration = 0
        part_num = 1
        
        if keywords is None:
            keywords = []
        if matched_keywords is None:
            matched_keywords = []
        
        for seg in segments:
            seg_duration = seg['end'] - seg['start']
            
            if current_duration + seg_duration > max_duration and current_segments:
                start_time = current_segments[0]['start']
                end_time = current_segments[-1]['end']
                full_text = ' '.join([s['text'] for s in current_segments])
                clip_keywords = self.extract_keywords(full_text, top_n=2) if not keywords else keywords
                
                clips.append({
                    'topic_id': f"{topic_id}-{part_num}",
                    'keywords': clip_keywords,
                    'matched_keywords': matched_keywords,
                    'text': full_text[:200],
                    'start': start_time,
                    'end': end_time,
                    'duration': end_time - start_time
                })
                
                current_segments = [seg]
                current_duration = seg_duration
                part_num += 1
            else:
                current_segments.append(seg)
                current_duration += seg_duration
        
        # ë§ˆì§€ë§‰ í´ë¦½
        if current_segments:
            start_time = current_segments[0]['start']
            end_time = current_segments[-1]['end']
            full_text = ' '.join([s['text'] for s in current_segments])
            clip_keywords = self.extract_keywords(full_text, top_n=2) if not keywords else keywords
            
            clips.append({
                'topic_id': f"{topic_id}-{part_num}",
                'keywords': clip_keywords,
                'matched_keywords': matched_keywords,
                'text': full_text[:200],
                'start': start_time,
                'end': end_time,
                'duration': end_time - start_time
            })
        
        return clips
    
    def create_shorts(self, topic_clips, vertical=True):
        """ìˆí¼ ì˜ìƒ ìƒì„±"""
        print(f"\nâœ‚ï¸  ìˆí¼ ì˜ìƒ ìƒì„± ì¤‘...")
        
        created_shorts = []
        
        for i, clip_info in enumerate(topic_clips, 1):
            start = clip_info['start']
            end = clip_info['end']
            duration = clip_info['duration']
            
            # íŒŒì¼ëª… ìƒì„± (ë§¤ì¹­ëœ í‚¤ì›Œë“œ ìš°ì„ )
            if clip_info.get('matched_keywords'):
                keyword_name = '_'.join(clip_info['matched_keywords'][:2])
            elif clip_info['keywords']:
                keyword_name = '_'.join(clip_info['keywords'][:2])
            else:
                keyword_name = 'topic'
            
            keyword_name = re.sub(r'[^\wê°€-í£]', '_', keyword_name)
            topic_id = clip_info.get('topic_id', i)
            output_filename = f"short_{i:03d}_{keyword_name}.mp4"
            output_path = os.path.join(self.output_dir, output_filename)
            
            print(f"\n   [{i}/{len(topic_clips)}] {output_filename}")
            print(f"      ì‹œê°„: {self._format_time(start)} ~ {self._format_time(end)} ({duration:.1f}ì´ˆ)")
            if clip_info.get('matched_keywords'):
                print(f"      âœ… ë§¤ì¹­: {', '.join(clip_info['matched_keywords'][:3])}")
            elif clip_info['keywords']:
                print(f"      í‚¤ì›Œë“œ: {', '.join(clip_info['keywords'][:3])}")
            
            try:
                if vertical:
                    success = self._create_vertical_clip(
                        self.video_path,
                        output_path,
                        start,
                        duration
                    )
                else:
                    success = self._create_clip(
                        self.video_path,
                        output_path,
                        start,
                        duration
                    )
                
                if success:
                    created_shorts.append({
                        'filename': output_filename,
                        'path': os.path.abspath(output_path),
                        'keywords': clip_info['keywords'],
                        'matched_keywords': clip_info.get('matched_keywords', []),
                        'text': clip_info['text'],
                        'start': start,
                        'end': end,
                        'duration': duration
                    })
                    print(f"      âœ… ì €ì¥ ì™„ë£Œ!")
                else:
                    print(f"      âŒ ìƒì„± ì‹¤íŒ¨")
                    
            except Exception as e:
                print(f"      âŒ ì˜¤ë¥˜: {e}")
                continue
        
        return created_shorts
    
    def _create_clip(self, input_path, output_path, start, duration):
        """ffmpegë¡œ ì˜ìƒ ìë¥´ê¸° (ì›ë³¸ ë¹„ìœ¨)"""
        cmd = [
            'ffmpeg',
            '-y',
            '-ss', str(start),
            '-i', input_path,
            '-t', str(duration),
            '-c:v', 'libx264',
            '-preset', 'medium',
            '-crf', '23',
            '-c:a', 'aac',
            '-b:a', '128k',
            '-movflags', '+faststart',
            output_path
        ]
        
        try:
            subprocess.run(
                cmd,
                check=True,
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL
            )
            return True
        except subprocess.CalledProcessError:
            return False
    
    def _create_vertical_clip(self, input_path, output_path, start, duration):
        """ffmpegë¡œ 9:16 ì„¸ë¡œ ì˜ìƒ ìƒì„±"""
        target_width = 1080
        target_height = 1920
        
        current_width = self.video_info['width']
        current_height = self.video_info['height']
        
        scale_for_width = target_height / current_height
        scale_for_height = target_width / current_width
        
        if current_width / current_height > target_width / target_height:
            scale = scale_for_width
            crop_width = int(target_width / scale)
            crop_height = current_height
            crop_x = int((current_width - crop_width) / 2)
            crop_y = 0
        else:
            scale = scale_for_height
            crop_width = current_width
            crop_height = int(target_height / scale)
            crop_x = 0
            crop_y = int((current_height - crop_height) / 2)
        
        cmd = [
            'ffmpeg',
            '-y',
            '-ss', str(start),
            '-i', input_path,
            '-t', str(duration),
            '-vf', f'crop={crop_width}:{crop_height}:{crop_x}:{crop_y},scale={target_width}:{target_height}',
            '-c:v', 'libx264',
            '-preset', 'medium',
            '-crf', '23',
            '-c:a', 'aac',
            '-b:a', '128k',
            '-movflags', '+faststart',
            output_path
        ]
        
        try:
            subprocess.run(
                cmd,
                check=True,
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL
            )
            return True
        except subprocess.CalledProcessError as e:
            print(f"      ffmpeg ì˜¤ë¥˜: {e}")
            return False
    
    def _format_time(self, seconds):
        """ì´ˆë¥¼ MM:SS í˜•ì‹ìœ¼ë¡œ"""
        return str(timedelta(seconds=int(seconds)))[2:]
    
    def create_fcpxml(self, shorts, output_file="topic_shorts.fcpxml"):
        """FCP XML í”„ë¡œì íŠ¸ íŒŒì¼ ìƒì„±"""
        print(f"\nğŸ“¦ Final Cut Pro í”„ë¡œì íŠ¸ ìƒì„± ì¤‘...")
        
        fcpxml_path = os.path.join(self.output_dir, output_file)
        
        fcpxml = ET.Element('fcpxml', version="1.11")
        resources = ET.SubElement(fcpxml, 'resources')
        
        format_elem = ET.SubElement(resources, 'format', {
            'id': 'r0',
            'name': 'FFVideoFormat1080p9x16',
            'frameDuration': '1001/30000s',
            'width': '1080',
            'height': '1920'
        })
        
        for i, short in enumerate(shorts, 1):
            asset = ET.SubElement(resources, 'asset', {
                'id': f'r{i}',
                'name': short['filename'],
                'uid': f'asset-{i}',
                'src': f"file://{short['path']}",
                'start': '0s',
                'duration': f"{short['duration']:.3f}s",
                'hasVideo': '1',
                'hasAudio': '1',
                'format': 'r0'
            })
        
        library = ET.SubElement(fcpxml, 'library')
        event = ET.SubElement(library, 'event', name='í™”ì œë³„ ìˆí¼')
        
        project = ET.SubElement(event, 'project', name='ìˆí¼ ëª¨ìŒ')
        sequence = ET.SubElement(project, 'sequence', {
            'format': 'r0',
            'tcStart': '0s',
            'tcFormat': 'NDF',
            'audioLayout': 'stereo',
            'audioRate': '48k'
        })
        
        spine = ET.SubElement(sequence, 'spine')
        
        for i, short in enumerate(shorts, 1):
            clip = ET.SubElement(spine, 'asset-clip', {
                'ref': f'r{i}',
                'offset': '0s',
                'name': short['filename'],
                'duration': f"{short['duration']:.3f}s",
                'format': 'r0',
                'tcFormat': 'NDF'
            })
            
            keywords_to_mark = short.get('matched_keywords', []) or short.get('keywords', [])
            if keywords_to_mark:
                keyword_text = ', '.join(keywords_to_mark)
                marker = ET.SubElement(clip, 'marker', {
                    'start': '0s',
                    'duration': '1/30s',
                    'value': keyword_text
                })
        
        xml_str = minidom.parseString(ET.tostring(fcpxml)).toprettyxml(indent="  ")
        
        with open(fcpxml_path, 'w', encoding='utf-8') as f:
            f.write(xml_str)
        
        print(f"âœ… FCPXML ìƒì„± ì™„ë£Œ: {fcpxml_path}")
        return fcpxml_path
    
    def save_report(self, shorts, filename="report.txt"):
        """ê²°ê³¼ ë¦¬í¬íŠ¸ ì €ì¥"""
        report_path = os.path.join(self.output_dir, filename)
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("=" * 60 + "\n")
            f.write("í™”ì œë³„ ìˆí¼ ìƒì„± ë¦¬í¬íŠ¸\n")
            f.write("=" * 60 + "\n\n")
            f.write(f"ì›ë³¸ ì˜ìƒ: {self.video_path}\n")
            f.write(f"ìƒì„±ëœ ìˆí¼: {len(shorts)}ê°œ\n")
            f.write(f"ìœ ì‚¬ë„ ì„ê³„ê°’: {self.similarity_threshold}\n")
            if self.keywords:
                f.write(f"í•„í„°ë§ í‚¤ì›Œë“œ: {len(self.keywords)}ê°œ\n\n")
            else:
                f.write(f"í•„í„°ë§ í‚¤ì›Œë“œ: ì—†ìŒ (ì „ì²´ í™”ì œ)\n\n")
            
            for i, short in enumerate(shorts, 1):
                f.write(f"\n[{i}] {short['filename']}\n")
                if short.get('matched_keywords'):
                    f.write(f"    âœ… ë§¤ì¹­ í‚¤ì›Œë“œ: {', '.join(short['matched_keywords'])}\n")
                if short.get('keywords'):
                    f.write(f"    ìë™ í‚¤ì›Œë“œ: {', '.join(short['keywords'])}\n")
                f.write(f"    ì‹œê°„: {self._format_time(short['start'])} ~ {self._format_time(short['end'])}\n")
                f.write(f"    ê¸¸ì´: {short['duration']:.1f}ì´ˆ\n")
                f.write(f"    ë‚´ìš©: {short['text']}\n")
                f.write("-" * 60 + "\n")
        
        print(f"ğŸ“„ ë¦¬í¬íŠ¸ ì €ì¥: {report_path}")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    # Segmentation fault ë°©ì§€
    os.environ["OMP_NUM_THREADS"] = "1"
    os.environ["MKL_NUM_THREADS"] = "1"
    
    try:
        torch.set_num_threads(1)
    except ImportError:
        pass
    
    # ==================== ì„¤ì • ====================
    VIDEO_PATH = "ë‚˜ì˜ ë™ì˜ìƒ.mov"
    OUTPUT_DIR = "topic_shorts"
    
    # í‚¤ì›Œë“œ í•„í„°ë§ (Noneì´ë©´ ì „ì²´ í™”ì œ ì¶”ì¶œ)
    KEYWORDS = [
        # Noneìœ¼ë¡œ ì„¤ì •í•˜ë©´ ëª¨ë“  í™”ì œ ì¶”ì¶œ
    ]
    
    USE_KEYWORD_FILTER = True  # Falseë¡œ ì„¤ì •í•˜ë©´ í‚¤ì›Œë“œ ë¬´ì‹œí•˜ê³  ì „ì²´ í™”ì œ ì¶”ì¶œ
    CONTEXT_SEGMENTS = 2  # í‚¤ì›Œë“œ ë°œê²¬ ì‹œ ì•ë’¤ë¡œ í¬í•¨í•  êµ¬ê°„ ìˆ˜
    
    VERTICAL = True
    MIN_DURATION = 15
    MAX_DURATION = 60
    SIMILARITY_THRESHOLD = 0.65
    # =============================================
    
    # ffmpeg ì„¤ì¹˜ í™•ì¸
    try:
        subprocess.run(['ffmpeg', '-version'], 
                      capture_output=True, check=True)
    except (subprocess.CalledProcessError, FileNotFoundError):
        print("âŒ ffmpegê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤!")
        print("\nì„¤ì¹˜ ë°©ë²•:")
        print("  Mac: brew install ffmpeg")
        print("  Windows: https://ffmpeg.org/download.html")
        return
    
    if not os.path.exists(VIDEO_PATH):
        print(f"âŒ ì˜ìƒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {VIDEO_PATH}")
        return
    
    print("ğŸ¬ í™”ì œ ê¸°ë°˜ ìˆí¼ ìë™ ìƒì„±ê¸° (í‚¤ì›Œë“œ í•„í„°ë§)")
    print("=" * 60)
    
    creator = TopicBasedShortCreator(
        VIDEO_PATH, 
        keywords=KEYWORDS if USE_KEYWORD_FILTER else None,
        output_dir=OUTPUT_DIR,
        similarity_threshold=SIMILARITY_THRESHOLD
    )
    
    # 1. ìŒì„± ì¸ì‹
    transcription = creator.transcribe_video()
    
    # 2. í™”ì œë³„ êµ¬ê°„ ì°¾ê¸°
    topic_clips = creator.find_topic_segments(
        transcription,
        min_duration=MIN_DURATION,
        max_duration=MAX_DURATION,
        use_keyword_filter=USE_KEYWORD_FILTER,
        context_segments=CONTEXT_SEGMENTS
    )
    
    if not topic_clips:
        print("\nâŒ ì¡°ê±´ì— ë§ëŠ” êµ¬ê°„ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        if USE_KEYWORD_FILTER and KEYWORDS:
            print(f"ğŸ’¡ íŒ: í‚¤ì›Œë“œë¥¼ ë” ì¶”ê°€í•˜ê±°ë‚˜ USE_KEYWORD_FILTER=Falseë¡œ ì„¤ì •í•´ë³´ì„¸ìš”")
        return
    
    # 3. ìˆí¼ ìƒì„±
    shorts = creator.create_shorts(topic_clips, vertical=VERTICAL)
    
    if not shorts:
        print("\nâŒ ìˆí¼ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return
    
    # 4. FCP í”„ë¡œì íŠ¸ ìƒì„±
    fcpxml_path = creator.create_fcpxml(shorts)
    
    # 5. ë¦¬í¬íŠ¸ ì €ì¥
    creator.save_report(shorts)
    
    # ì™„ë£Œ!
    print("\n" + "=" * 60)
    print("ğŸ‰ ì™„ë£Œ!")
    print("=" * 60)
    print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {os.path.abspath(OUTPUT_DIR)}")
    print(f"ğŸ“Š ìƒì„±ëœ ìˆí¼: {len(shorts)}ê°œ")
    print(f"\nğŸ’¡ ì„¤ì •:")
    print(f"   - í™”ì œ ì „í™˜ ì„ê³„ê°’: {SIMILARITY_THRESHOLD}")
    print(f"   - í‚¤ì›Œë“œ í•„í„°ë§: {'ON' if USE_KEYWORD_FILTER and KEYWORDS else 'OFF'}")
    if USE_KEYWORD_FILTER and KEYWORDS:
        print(f"   - í•„í„°ë§ í‚¤ì›Œë“œ: {len(KEYWORDS)}ê°œ")
        print(f"   - ì»¨í…ìŠ¤íŠ¸ í™•ì¥: ì•ë’¤ {CONTEXT_SEGMENTS}êµ¬ê°„")
    print(f"\nìƒì„±ëœ íŒŒì¼:")
    for i, short in enumerate(shorts[:10], 1):
        matched = short.get('matched_keywords', [])
        marker = f" [âœ… {', '.join(matched[:2])}]" if matched else ""
        print(f"  {short['filename']} ({short['duration']:.1f}ì´ˆ){marker}")
    if len(shorts) > 10:
        print(f"  ... ì™¸ {len(shorts)-10}ê°œ")
    print(f"\nğŸ¬ {fcpxml_path}ì„ Final Cut Proì—ì„œ ì—´ì–´ë³´ì„¸ìš”!")
    print("=" * 60)


if __name__ == "__main__":
    try:
        import whisper
        from sentence_transformers import SentenceTransformer
        from sklearn.feature_extraction.text import TfidfVectorizer
    except ImportError:
        print("âŒ í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•´ì£¼ì„¸ìš”:")
        print("\npip install openai-whisper sentence-transformers scikit-learn")
        exit(1)
    main()
