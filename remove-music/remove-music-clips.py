"""
ê¸´ ì˜ìƒì—ì„œ ìŒì•… êµ¬ê°„ë³„ë¡œ ë°°ê²½ìŒì•… ì œê±°
Long Video Music Removal by Section

ì‘ë™ ë°©ì‹:
1. ê¸´ ì˜ìƒ ë¶„ì„
2. ìŒì•… ë³€í™” ì§€ì  ìë™ ê°ì§€
3. ê° êµ¬ê°„ë³„ë¡œ ìŒì•… ìƒ˜í”Œ ì¶”ì¶œ
4. êµ¬ê°„ë³„ë¡œ ìŒì•… ì œê±° ì ìš©
5. ì „ì²´ ì˜ìƒ í•©ì¹˜ê¸°

í•„ìš”í•œ ì„¤ì¹˜:
pip install librosa soundfile noisereduce pydub webrtcvad numpy scipy
brew install ffmpeg
"""

import os
import subprocess
import numpy as np
import librosa
import soundfile as sf
import noisereduce as nr
from pydub import AudioSegment
import webrtcvad
from scipy import signal
from scipy.cluster.hierarchy import linkage, fcluster


class LongVideoMusicRemover:
    def __init__(self):
        self.temp_folder = "./temp_processing"
        os.makedirs(self.temp_folder, exist_ok=True)
    
    def extract_audio_ffmpeg(self, video_path, audio_path, sample_rate=22050):
        """FFmpegë¡œ ì˜ìƒì—ì„œ ì˜¤ë””ì˜¤ ì¶”ì¶œ"""
        print("ğŸ“¤ ì˜¤ë””ì˜¤ ì¶”ì¶œ ì¤‘...")
        cmd = [
            'ffmpeg', '-i', video_path,
            '-vn', '-acodec', 'pcm_s16le',
            '-ar', str(sample_rate), '-ac', '1',
            '-y', audio_path
        ]
        subprocess.run(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        print("âœ“ ì˜¤ë””ì˜¤ ì¶”ì¶œ ì™„ë£Œ")
    
    def detect_voice_segments_vad(self, audio_path):
        """VADë¡œ ëª©ì†Œë¦¬ êµ¬ê°„ ë¹ ë¥´ê²Œ ê°ì§€"""
        print("ğŸ¤ ëª©ì†Œë¦¬ êµ¬ê°„ ê°ì§€ ì¤‘...")
        
        # 16kHzë¡œ ë³€í™˜ (VAD ìš”êµ¬ì‚¬í•­)
        audio_16k = AudioSegment.from_wav(audio_path)
        audio_16k = audio_16k.set_frame_rate(16000).set_channels(1)
        
        temp_16k = os.path.join(self.temp_folder, "temp_16k.wav")
        audio_16k.export(temp_16k, format="wav")
        
        vad = webrtcvad.Vad(2)  # ì¤‘ê°„ ë¯¼ê°ë„
        
        frame_duration = 30
        voice_frames = []
        
        for i in range(0, len(audio_16k), frame_duration):
            frame = audio_16k[i:i+frame_duration]
            if len(frame.raw_data) >= int(16000 * frame_duration / 1000) * 2:
                is_speech = vad.is_speech(frame.raw_data, 16000)
                voice_frames.append(1 if is_speech else 0)
        
        os.remove(temp_16k)
        
        print(f"âœ“ ëª©ì†Œë¦¬ ê°ì§€ ì™„ë£Œ")
        return voice_frames
    
    def detect_music_change_points(self, audio_path, min_section_duration=10):
        """
        ìŒì•…ì´ ë°”ë€ŒëŠ” ì§€ì  ìë™ ê°ì§€
        min_section_duration: ìµœì†Œ êµ¬ê°„ ê¸¸ì´ (ì´ˆ)
        """
        print("ğŸµ ìŒì•… ë³€í™” ì§€ì  ê°ì§€ ì¤‘...")
        
        # ì˜¤ë””ì˜¤ ë¡œë“œ
        y, sr = librosa.load(audio_path, sr=22050, mono=True)
        
        # í¬ë¡œë§ˆ íŠ¹ì„± ì¶”ì¶œ (ìŒì•…ì˜ ìŒë†’ì´ íŒ¨í„´)
        chroma = librosa.feature.chroma_cqt(y=y, sr=sr, hop_length=4096)
        
        # ì‹œê°„ ìœˆë„ìš°ë³„ë¡œ í‰ê·  ê³„ì‚° (5ì´ˆ ìœˆë„ìš°)
        window_size = int(5 * sr / 4096)  # 5ì´ˆ
        
        chroma_windows = []
        for i in range(0, chroma.shape[1] - window_size, window_size // 2):
            window = chroma[:, i:i+window_size]
            chroma_windows.append(np.mean(window, axis=1))
        
        chroma_windows = np.array(chroma_windows)
        
        # ìœ ì‚¬ë„ ê³„ì‚°
        similarities = []
        for i in range(len(chroma_windows) - 1):
            sim = np.dot(chroma_windows[i], chroma_windows[i+1])
            similarities.append(sim)
        
        similarities = np.array(similarities)
        
        # ê¸‰ê²©í•œ ë³€í™” ì§€ì  ì°¾ê¸° (ìŒì•…ì´ ë°”ë€ŒëŠ” ê³³)
        threshold = np.percentile(similarities, 20)  # í•˜ìœ„ 20%
        change_points = np.where(similarities < threshold)[0]
        
        # ì‹œê°„ìœ¼ë¡œ ë³€í™˜ (ì´ˆ)
        time_per_window = (window_size / 2) * 4096 / sr
        change_times = [int(cp * time_per_window) for cp in change_points]
        
        # ë„ˆë¬´ ê°€ê¹Œìš´ ì§€ì ë“¤ ë³‘í•©
        merged_times = [0]
        for t in change_times:
            if t - merged_times[-1] >= min_section_duration:
                merged_times.append(t)
        
        # ë§ˆì§€ë§‰ ì§€ì  ì¶”ê°€
        total_duration = int(len(y) / sr)
        if total_duration - merged_times[-1] >= min_section_duration:
            merged_times.append(total_duration)
        
        # êµ¬ê°„ìœ¼ë¡œ ë³€í™˜
        sections = []
        for i in range(len(merged_times) - 1):
            sections.append((merged_times[i], merged_times[i+1]))
        
        print(f"âœ“ ê°ì§€ëœ ìŒì•… êµ¬ê°„: {len(sections)}ê°œ")
        for i, (start, end) in enumerate(sections, 1):
            duration = end - start
            print(f"   êµ¬ê°„ {i}: {start//60:02d}:{start%60:02d} ~ {end//60:02d}:{end%60:02d} ({duration}ì´ˆ)")
        
        return sections
    
    def extract_music_sample_from_section(self, y, sr, start_time, end_time, voice_frames, sample_duration=3):
        """
        íŠ¹ì • êµ¬ê°„ì—ì„œ ëª©ì†Œë¦¬ ì—†ëŠ” ë¶€ë¶„ì˜ ìŒì•… ìƒ˜í”Œ ì¶”ì¶œ
        """
        start_sample = int(start_time * sr)
        end_sample = int(end_time * sr)
        
        section_audio = y[start_sample:end_sample]
        
        # ì´ êµ¬ê°„ì˜ VAD í”„ë ˆì„
        frame_rate = len(voice_frames) / len(y)
        section_start_frame = int(start_sample * frame_rate)
        section_end_frame = int(end_sample * frame_rate)
        section_voice_frames = voice_frames[section_start_frame:section_end_frame]
        
        # ëª©ì†Œë¦¬ ì—†ëŠ” ë¶€ë¶„ ì°¾ê¸° (ì—°ì† 50í”„ë ˆì„ ì´ìƒ)
        music_only_regions = []
        in_music = False
        music_start = 0
        
        for i, is_voice in enumerate(section_voice_frames):
            if not is_voice:
                if not in_music:
                    music_start = i
                    in_music = True
            else:
                if in_music and (i - music_start) > 50:
                    music_only_regions.append((music_start, i))
                in_music = False
        
        # ìƒ˜í”Œ ì¶”ì¶œ
        if music_only_regions:
            # ê°€ì¥ ê¸´ ìŒì•… ì „ìš© êµ¬ê°„ ì„ íƒ
            longest = max(music_only_regions, key=lambda x: x[1] - x[0])
            
            # í”„ë ˆì„ì„ ìƒ˜í”Œë¡œ ë³€í™˜
            sample_start = int(longest[0] / frame_rate)
            sample_end = int(longest[1] / frame_rate)
            
            # ìƒ˜í”Œ ì¶”ì¶œ
            sample_len = int(sample_duration * sr)
            if sample_end - sample_start > sample_len:
                mid = (sample_start + sample_end) // 2
                sample = section_audio[mid:mid + sample_len]
                return sample
        
        # ìŒì•… ì „ìš© êµ¬ê°„ ì—†ìœ¼ë©´ êµ¬ê°„ ì¤‘ê°„ì—ì„œ ì¶”ì¶œ
        mid = len(section_audio) // 2
        sample_len = int(sample_duration * sr)
        return section_audio[mid:mid + sample_len]
    
    def remove_music_from_section(self, y, sr, music_sample, prop_decrease=0.9):
        """
        ìŒì•… ìƒ˜í”Œì„ ì‚¬ìš©í•˜ì—¬ ë…¸ì´ì¦ˆ ë¦¬ë•ì…˜
        """
        reduced = nr.reduce_noise(
            y=y,
            sr=sr,
            y_noise=music_sample,
            stationary=True,
            prop_decrease=prop_decrease
        )
        return reduced
    
    def process_long_video(self, video_path, output_path, min_section_duration=10):
        """
        ê¸´ ì˜ìƒ ì „ì²´ ì²˜ë¦¬
        """
        print("\n" + "="*70)
        print("ğŸ¬ ê¸´ ì˜ìƒ ìŒì•… ì œê±° í”„ë¡œì„¸ìŠ¤ ì‹œì‘")
        print("="*70)
        print(f"ì…ë ¥: {video_path}")
        print(f"ì¶œë ¥: {output_path}")
        print("="*70 + "\n")
        
        # 1. ì˜¤ë””ì˜¤ ì¶”ì¶œ
        temp_audio = os.path.join(self.temp_folder, "full_audio.wav")
        self.extract_audio_ffmpeg(video_path, temp_audio, sample_rate=22050)
        
        # 2. ëª©ì†Œë¦¬ êµ¬ê°„ ê°ì§€ (VAD)
        temp_audio_16k = os.path.join(self.temp_folder, "full_audio_16k.wav")
        self.extract_audio_ffmpeg(video_path, temp_audio_16k, sample_rate=16000)
        voice_frames = self.detect_voice_segments_vad(temp_audio_16k)
        
        # 3. ìŒì•… ë³€í™” ì§€ì  ê°ì§€
        music_sections = self.detect_music_change_points(temp_audio, min_section_duration)
        
        # 4. ì „ì²´ ì˜¤ë””ì˜¤ ë¡œë“œ
        print("\nğŸ“Š ì „ì²´ ì˜¤ë””ì˜¤ ë¡œë”©...")
        y, sr = librosa.load(temp_audio, sr=22050, mono=True)
        print(f"âœ“ ë¡œë“œ ì™„ë£Œ (ê¸¸ì´: {len(y)/sr:.1f}ì´ˆ)")
        
        # 5. ê° êµ¬ê°„ë³„ë¡œ ì²˜ë¦¬
        print("\nğŸ”§ êµ¬ê°„ë³„ ìŒì•… ì œê±° ì‹œì‘...\n")
        processed_sections = []
        
        for i, (start_time, end_time) in enumerate(music_sections, 1):
            print(f"{'='*60}")
            print(f"êµ¬ê°„ {i}/{len(music_sections)}: {start_time}ì´ˆ ~ {end_time}ì´ˆ")
            print(f"{'='*60}")
            
            # êµ¬ê°„ ì¶”ì¶œ
            start_sample = int(start_time * sr)
            end_sample = int(end_time * sr)
            section_audio = y[start_sample:end_sample]
            
            # ì´ êµ¬ê°„ì˜ ìŒì•… ìƒ˜í”Œ ì¶”ì¶œ
            print("  â†’ ìŒì•… ìƒ˜í”Œ ì¶”ì¶œ ì¤‘...")
            music_sample = self.extract_music_sample_from_section(
                y, sr, start_time, end_time, voice_frames
            )
            
            # ìŒì•… ì œê±°
            print("  â†’ ìŒì•… ì œê±° ì¤‘...")
            cleaned = self.remove_music_from_section(section_audio, sr, music_sample, prop_decrease=0.95)
            
            processed_sections.append(cleaned)
            print(f"  âœ“ êµ¬ê°„ {i} ì™„ë£Œ\n")
        
        # 6. ëª¨ë“  êµ¬ê°„ í•©ì¹˜ê¸°
        print("ğŸ”— ëª¨ë“  êµ¬ê°„ í•©ì¹˜ëŠ” ì¤‘...")
        final_audio = np.concatenate(processed_sections)
        
        # 7. ì²˜ë¦¬ëœ ì˜¤ë””ì˜¤ ì €ì¥
        cleaned_audio_path = os.path.join(self.temp_folder, "cleaned_audio.wav")
        sf.write(cleaned_audio_path, final_audio, sr)
        print("âœ“ ì²˜ë¦¬ëœ ì˜¤ë””ì˜¤ ì €ì¥ ì™„ë£Œ")
        
        # 8. ì˜ìƒê³¼ í•©ì¹˜ê¸°
        print("\nğŸ¥ ì˜ìƒê³¼ ì˜¤ë””ì˜¤ ê²°í•© ì¤‘...")
        cmd = [
            'ffmpeg', '-i', video_path,
            '-i', cleaned_audio_path,
            '-c:v', 'copy',
            '-c:a', 'aac',
            '-b:a', '192k',
            '-map', '0:v:0',
            '-map', '1:a:0',
            '-shortest',
            '-y',
            output_path
        ]
        subprocess.run(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        
        print("âœ“ ì˜ìƒ ê²°í•© ì™„ë£Œ")
        
        # 9. ì •ë¦¬
        print("\nğŸ§¹ ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì¤‘...")
        import shutil
        if os.path.exists(self.temp_folder):
            shutil.rmtree(self.temp_folder)
        
        print("\n" + "="*70)
        print("ğŸ‰ ì™„ë£Œ!")
        print("="*70)
        print(f"âœ… ê²°ê³¼ íŒŒì¼: {output_path}")
        print(f"ğŸ“Š ì²˜ë¦¬ëœ êµ¬ê°„: {len(music_sections)}ê°œ")
        print("="*70)


def main():
    print("""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘   ğŸµ ê¸´ ì˜ìƒ ìŒì•… êµ¬ê°„ë³„ ì œê±° ë„êµ¬ ğŸµ                 â•‘
    â•‘   ìë™ìœ¼ë¡œ ìŒì•… ë³€í™” ê°ì§€ + êµ¬ê°„ë³„ ì œê±°              â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    video_path = input("\nì›ë³¸ ê¸´ ì˜ìƒ ê²½ë¡œ: ").strip()
    
    if not os.path.exists(video_path):
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")
        return
    
    # ì¶œë ¥ íŒŒì¼ëª… ìë™ ìƒì„±
    base_name = os.path.splitext(video_path)[0]
    output_path = f"{base_name}_music_removed.mp4"
    
    print(f"\nê²°ê³¼ íŒŒì¼: {output_path}")
    
    # ìµœì†Œ êµ¬ê°„ ê¸¸ì´ ì„¤ì •
    min_duration = input("ìµœì†Œ êµ¬ê°„ ê¸¸ì´(ì´ˆ) (ê¸°ë³¸ê°’: 10): ").strip()
    min_duration = int(min_duration) if min_duration else 10
    
    # ì²˜ë¦¬ ì‹œì‘
    remover = LongVideoMusicRemover()
    remover.process_long_video(video_path, output_path, min_section_duration=min_duration)


if __name__ == "__main__":
    main()


"""
ì‘ë™ ì›ë¦¬:

1. ğŸµ ìŒì•… ë³€í™” ê°ì§€
   - í¬ë¡œë§ˆ íŠ¹ì„± ë¶„ì„ (ìŒë†’ì´ íŒ¨í„´)
   - ê¸‰ê²©í•œ ë³€í™” ì§€ì  = ìŒì•…ì´ ë°”ë€ŒëŠ” ê³³
   - ìë™ìœ¼ë¡œ êµ¬ê°„ ë¶„í• 

2. ğŸ¤ ëª©ì†Œë¦¬ êµ¬ê°„ ê°ì§€
   - VADë¡œ ì „ì²´ ì˜ìƒ ë¶„ì„
   - ê° êµ¬ê°„ì—ì„œ ëª©ì†Œë¦¬ ì—†ëŠ” ë¶€ë¶„ ì°¾ê¸°

3. ğŸ”§ êµ¬ê°„ë³„ ì²˜ë¦¬
   - ê° ìŒì•… êµ¬ê°„ë§ˆë‹¤:
     * ëª©ì†Œë¦¬ ì—†ëŠ” ë¶€ë¶„ì—ì„œ ìŒì•… ìƒ˜í”Œ ì¶”ì¶œ
     * í•´ë‹¹ ìƒ˜í”Œë¡œ ë…¸ì´ì¦ˆ ë¦¬ë•ì…˜
     * ìŒì•…ë§Œ ì„ íƒì ìœ¼ë¡œ ì œê±°

4. ğŸ”— êµ¬ê°„ í•©ì¹˜ê¸°
   - ëª¨ë“  ì²˜ë¦¬ëœ êµ¬ê°„ì„ ì—°ê²°
   - ìµœì¢… ì˜ìƒ ìƒì„±

ì¥ì :
âœ… ìŒì•… êµ¬ê°„ ìë™ ê°ì§€
âœ… ì—¬ëŸ¬ ë‹¤ë¥¸ ë…¸ë˜ ëª¨ë‘ ì œê±°
âœ… êµ¬ê°„ë³„ë¡œ ìµœì í™”ëœ ì œê±°
âœ… ëª©ì†Œë¦¬ ìµœëŒ€í•œ ë³´ì¡´
âœ… í•œ ë²ˆì— ì „ì²´ ì²˜ë¦¬

ì˜ˆìƒ ê²°ê³¼:
- ë°°ê²½ ìŒì•…: 80-90% ì œê±°
- ëª©ì†Œë¦¬: ê±°ì˜ ì†ìƒ ì—†ìŒ
- ì²˜ë¦¬ ì‹œê°„: ì˜ìƒ ê¸¸ì´ì˜ 2-3ë°°

ì„¤ì¹˜:
pip install librosa soundfile noisereduce pydub webrtcvad numpy scipy
brew install ffmpeg

ì‚¬ìš©:
python long_video_music_remover.py
â†’ ì›ë³¸ ê¸´ ì˜ìƒ ì…ë ¥
â†’ ìë™ ì²˜ë¦¬
â†’ ì™„ë£Œ!
"""