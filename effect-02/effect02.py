# -*- coding: utf-8 -*-

import os
import json
import subprocess
from datetime import timedelta
from faster_whisper import WhisperModel
from pathlib import Path
import xml.etree.ElementTree as ET
from xml.dom import minidom
import torch
import numpy as np
from sentence_transformers import SentenceTransformer
from collections import Counter
import re

class TopicBasedShortCreator:
    def __init__(self, video_path, output_dir="shorts", similarity_threshold=0.7):
        self.video_path = video_path
        self.output_dir = output_dir
        self.similarity_threshold = similarity_threshold
        self.transcription_file = "transcription.json"
        os.makedirs(output_dir, exist_ok=True)
        
        # ì˜ë¯¸ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
        print("ğŸ¤– ë¬¸ì¥ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì¤‘...")
        self.embedding_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
        
        # ë¹„ë””ì˜¤ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        self.video_info = self._get_video_info()
        
    def _get_video_info(self):
        """ffprobeë¡œ ë¹„ë””ì˜¤ ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""
        cmd = [
            'ffprobe',
            '-v', 'quiet',
            '-print_format', 'json',
            '-show_format',
            '-show_streams',
            self.video_path
        ]
        
        try:
            result = subprocess.run(cmd, capture_output=True, text=True, check=True)
            info = json.loads(result.stdout)
            
            video_stream = None
            for stream in info['streams']:
                if stream['codec_type'] == 'video':
                    video_stream = stream
                    break
            
            return {
                'duration': float(info['format']['duration']),
                'width': int(video_stream['width']),
                'height': int(video_stream['height'])
            }
        except Exception as e:
            print(f"âš ï¸  ë¹„ë””ì˜¤ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
            return {'duration': 0, 'width': 1920, 'height': 1080}
    
    def transcribe_video(self, force_new=False):
        """ì˜ìƒ ìŒì„± ì¸ì‹ (faster-whisper ì‚¬ìš©)"""
        if os.path.exists(self.transcription_file) and not force_new:
            print("ğŸ“„ ê¸°ì¡´ ìë§‰ íŒŒì¼ ë¡œë“œ ì¤‘...")
            with open(self.transcription_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        
        print("ğŸ¤ ìŒì„± ì¸ì‹ ì‹œì‘... (faster-whisper ì‚¬ìš©)")
        print("   âš¡ ê¸°ì¡´ Whisperë³´ë‹¤ 4-5ë°° ë¹ ë¦…ë‹ˆë‹¤!")
        
        # faster-whisper ëª¨ë¸ ë¡œë“œ
        # compute_type: "int8" (CPU ìµœì í™”), "float16" (GPU), "float32" (ì •í™•ë„ ìš°ì„ )
        model = WhisperModel(
            "base", 
            device="cpu", 
            compute_type="int8"
        )
        
        # ìŒì„± ì¸ì‹ ìˆ˜í–‰
        segments_generator, info = model.transcribe(
            self.video_path,
            language="ko",
            word_timestamps=True,
            vad_filter=True,  # ìŒì„± êµ¬ê°„ ìë™ ê°ì§€
            beam_size=5
        )
        
        # generatorë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ê³  Whisper í˜•ì‹ì— ë§ê²Œ ë³€í™˜
        segments = []
        for segment in segments_generator:
            segments.append({
                'id': segment.id,
                'start': segment.start,
                'end': segment.end,
                'text': segment.text,
                'words': [
                    {
                        'start': word.start,
                        'end': word.end,
                        'word': word.word,
                        'probability': word.probability
                    }
                    for word in (segment.words or [])
                ] if segment.words else []
            })
        
        result = {
            'segments': segments,
            'language': info.language,
            'language_probability': info.language_probability,
            'duration': info.duration
        }
        
        # ê²°ê³¼ ì €ì¥
        with open(self.transcription_file, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… ìŒì„± ì¸ì‹ ì™„ë£Œ! (ì´ {len(segments)}ê°œ êµ¬ê°„)")
        print(f"   ì–¸ì–´: {info.language} (í™•ë¥ : {info.language_probability:.2%})")
        print(f"   ì˜ìƒ ê¸¸ì´: {info.duration:.1f}ì´ˆ")
        
        return result
    
    def find_topic_boundaries(self, segments, window_size=3):
        """ì˜ë¯¸ì  ìœ ì‚¬ë„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í™”ì œ ì „í™˜ì  ì°¾ê¸°"""
        print(f"\nğŸ” í™”ì œ ì „í™˜ì  ë¶„ì„ ì¤‘...")
        
        if len(segments) < 2:
            return [0, len(segments)]
        
        # ê° ì„¸ê·¸ë¨¼íŠ¸ì˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        texts = [seg['text'].strip() for seg in segments if seg['text'].strip()]
        
        if len(texts) < 2:
            return [0, len(segments)]
        
        # ë¬¸ì¥ ì„ë² ë”© ìƒì„±
        print("   ğŸ“Š ë¬¸ì¥ ì„ë² ë”© ìƒì„± ì¤‘...")
        embeddings = self.embedding_model.encode(texts, show_progress_bar=False)
        
        # ì—°ì†ëœ ì„¸ê·¸ë¨¼íŠ¸ ê°„ ìœ ì‚¬ë„ ê³„ì‚°
        similarities = []
        for i in range(len(embeddings) - 1):
            start_idx = max(0, i - window_size + 1)
            end_idx = min(len(embeddings), i + window_size + 1)
            
            window1 = np.mean(embeddings[start_idx:i+1], axis=0)
            window2 = np.mean(embeddings[i+1:end_idx], axis=0)
            
            similarity = np.dot(window1, window2) / (
                np.linalg.norm(window1) * np.linalg.norm(window2)
            )
            similarities.append(similarity)
        
        # ìœ ì‚¬ë„ê°€ ë‚®ì€ ì§€ì  = í™”ì œ ì „í™˜ì 
        boundaries = [0]
        for i, sim in enumerate(similarities):
            if sim < self.similarity_threshold:
                boundaries.append(i + 1)
                print(f"   âœ… í™”ì œ ì „í™˜ ê°ì§€: {i+1}ë²ˆì§¸ êµ¬ê°„ (ìœ ì‚¬ë„: {sim:.2f})")
        
        boundaries.append(len(segments))
        
        print(f"\nğŸ“Œ ì´ {len(boundaries)-1}ê°œì˜ í™”ì œ êµ¬ê°„ ë°œê²¬")
        return boundaries
    
    def extract_keywords(self, text, top_n=3):
        """í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        text = re.sub(r'[^\w\sê°€-í£]', ' ', text)
        
        stop_words = ['ì€', 'ëŠ”', 'ì´', 'ê°€', 'ì„', 'ë¥¼', 'ì—', 'ì˜', 'ì™€', 'ê³¼', 
                      'ë„', 'ìœ¼ë¡œ', 'ë¡œ', 'ì—ì„œ', 'í•˜ë‹¤', 'ìˆë‹¤', 'ë˜ë‹¤', 'ì´ë‹¤',
                      'ê·¸', 'ì €', 'ê²ƒ', 'ìˆ˜', 'ë“±', 'ë°', 'ì¢€', 'ë§‰', 'ì§„ì§œ', 'ë˜ê²Œ']
        
        words = text.split()
        words = [w for w in words if len(w) > 1 and w not in stop_words]
        
        if not words:
            return []
        
        word_counts = Counter(words)
        return [word for word, count in word_counts.most_common(top_n)]
    
    def find_topic_segments(self, transcription, min_duration=15, max_duration=60):
        """
        í™”ì œ ë‹¨ìœ„ë¡œ ëª¨ë“  êµ¬ê°„ ë¶„í•  (í‚¤ì›Œë“œ í•„í„°ë§ ì—†ìŒ)
        """
        segments = transcription['segments']
        
        # 1. í™”ì œ ê²½ê³„ ì°¾ê¸°
        boundaries = self.find_topic_boundaries(segments)
        
        # 2. ê° í™”ì œë¥¼ ìˆí¼ êµ¬ê°„ìœ¼ë¡œ ë³€í™˜
        topic_clips = []
        
        print(f"\nâœ‚ï¸  í™”ì œë³„ êµ¬ê°„ ìƒì„± ì¤‘ (í‚¤ì›Œë“œ í•„í„°ë§ ì—†ìŒ - ëª¨ë“  í™”ì œ í¬í•¨)...")
        
        for i in range(len(boundaries) - 1):
            start_idx = boundaries[i]
            end_idx = boundaries[i + 1]
            
            if start_idx >= len(segments) or end_idx > len(segments):
                continue
            
            # í™”ì œ ë‚´ ëª¨ë“  ì„¸ê·¸ë¨¼íŠ¸ í•©ì¹˜ê¸°
            topic_segments = segments[start_idx:end_idx]
            
            if not topic_segments:
                continue
            
            # ì „ì²´ í…ìŠ¤íŠ¸
            full_text = ' '.join([s['text'] for s in topic_segments])
            
            start_time = topic_segments[0]['start']
            end_time = topic_segments[-1]['end']
            duration = end_time - start_time
            
            # ê¸¸ì´ ì¡°ê±´ í™•ì¸
            if duration < min_duration:
                print(f"   â­ï¸  í™”ì œ {i+1}: ë„ˆë¬´ ì§§ìŒ ({duration:.1f}ì´ˆ < {min_duration}ì´ˆ)")
                continue
            
            # ìµœëŒ€ ê¸¸ì´ ì´ˆê³¼ ì‹œ ë¶„í• 
            if duration > max_duration:
                # ê¸´ í™”ì œë¥¼ ì—¬ëŸ¬ ê°œì˜ ìˆí¼ìœ¼ë¡œ ë¶„í• 
                sub_clips = self._split_long_topic(
                    topic_segments, 
                    start_time, 
                    end_time, 
                    max_duration
                )
                topic_clips.extend(sub_clips)
            else:
                # ìë™ í‚¤ì›Œë“œ ì¶”ì¶œ
                keywords = self.extract_keywords(full_text)
                
                topic_clips.append({
                    'start': start_time,
                    'end': end_time,
                    'duration': duration,
                    'text': full_text,
                    'keywords': keywords,
                    'topic_id': i + 1
                })
                
                print(f"   âœ… í™”ì œ {i+1}: {duration:.1f}ì´ˆ | í‚¤ì›Œë“œ: {', '.join(keywords)}")
        
        print(f"\nâœ… ì´ {len(topic_clips)}ê°œì˜ ìˆí¼ êµ¬ê°„ ìƒì„± ì™„ë£Œ")
        return topic_clips
    
    def _split_long_topic(self, segments, start_time, end_time, max_duration):
        """ê¸´ í™”ì œë¥¼ ì—¬ëŸ¬ ê°œì˜ ìˆí¼ìœ¼ë¡œ ë¶„í• """
        clips = []
        current_start = start_time
        current_segments = []
        current_duration = 0
        
        for seg in segments:
            seg_duration = seg['end'] - seg['start']
            
            if current_duration + seg_duration > max_duration and current_segments:
                # í˜„ì¬ êµ¬ê°„ ì €ì¥
                text = ' '.join([s['text'] for s in current_segments])
                keywords = self.extract_keywords(text)
                
                clips.append({
                    'start': current_start,
                    'end': current_segments[-1]['end'],
                    'duration': current_segments[-1]['end'] - current_start,
                    'text': text,
                    'keywords': keywords,
                    'topic_id': len(clips) + 1
                })
                
                # ìƒˆ êµ¬ê°„ ì‹œì‘
                current_start = seg['start']
                current_segments = [seg]
                current_duration = seg_duration
            else:
                current_segments.append(seg)
                current_duration += seg_duration
        
        # ë§ˆì§€ë§‰ êµ¬ê°„ ì €ì¥
        if current_segments:
            text = ' '.join([s['text'] for s in current_segments])
            keywords = self.extract_keywords(text)
            
            clips.append({
                'start': current_start,
                'end': current_segments[-1]['end'],
                'duration': current_segments[-1]['end'] - current_start,
                'text': text,
                'keywords': keywords,
                'topic_id': len(clips) + 1
            })
        
        return clips
    
    def _format_time(self, seconds):
        """ì´ˆë¥¼ HH:MM:SS í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        td = timedelta(seconds=seconds)
        hours = td.seconds // 3600
        minutes = (td.seconds % 3600) // 60
        secs = td.seconds % 60
        return f"{hours:02d}:{minutes:02d}:{secs:02d}"
    
    def _generate_filename(self, keywords, index, max_length=50):
        """í‚¤ì›Œë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ íŒŒì¼ëª… ìƒì„±"""
        if not keywords:
            return f"short_{index:03d}"
        
        # í‚¤ì›Œë“œë¥¼ ì–¸ë”ìŠ¤ì½”ì–´ë¡œ ì—°ê²°
        keyword_part = "_".join(keywords[:3])  # ìµœëŒ€ 3ê°œ í‚¤ì›Œë“œ ì‚¬ìš©
        
        # íŒŒì¼ëª…ì— ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ë¬¸ì ì œê±°
        keyword_part = re.sub(r'[^\wê°€-í£]', '_', keyword_part)
        
        # ê¸¸ì´ ì œí•œ
        if len(keyword_part) > max_length:
            keyword_part = keyword_part[:max_length]
        
        # ë²ˆí˜¸ì™€ í‚¤ì›Œë“œ ì¡°í•©
        return f"short_{index:03d}_{keyword_part}"
    
    def create_shorts(self, clips, vertical=True):
        """ìˆí¼ ì˜ìƒ ìƒì„±"""
        if not clips:
            return []
        
        print(f"\nğŸ¬ ìˆí¼ ì˜ìƒ ìƒì„± ì¤‘...")
        shorts = []
        
        for i, clip in enumerate(clips, 1):
            # í‚¤ì›Œë“œ ê¸°ë°˜ íŒŒì¼ëª… ìƒì„±
            keywords = clip.get('keywords', [])
            filename_base = self._generate_filename(keywords, i)
            filename = f"{filename_base}.mp4"
            output_path = os.path.join(self.output_dir, filename)
            
            # ì„¸ë¡œ ì˜ìƒ ì—¬ë¶€ì— ë”°ë¥¸ í•„í„° ì„¤ì •
            if vertical:
                # 9:16 ì„¸ë¡œ ë¹„ìœ¨ë¡œ í¬ë¡­
                crop_filter = f"scale={self.video_info['height']*9//16}:{self.video_info['height']},crop={self.video_info['height']*9//16}:{self.video_info['height']}"
            else:
                crop_filter = "scale=1080:1920"
            
            cmd = [
                'ffmpeg',
                '-y',
                '-ss', str(clip['start']),
                '-i', self.video_path,
                '-t', str(clip['duration']),
                '-vf', crop_filter,
                '-c:v', 'libx264',
                '-preset', 'fast',
                '-crf', '23',
                '-c:a', 'aac',
                '-b:a', '128k',
                '-movflags', '+faststart',
                output_path
            ]
            
            try:
                subprocess.run(
                    cmd, 
                    capture_output=True, 
                    check=True,
                    encoding='utf-8'
                )
                
                shorts.append({
                    'filename': filename,
                    'path': output_path,
                    'start': clip['start'],
                    'end': clip['end'],
                    'duration': clip['duration'],
                    'text': clip['text'],
                    'keywords': clip.get('keywords', []),
                    'topic_id': clip.get('topic_id', i)
                })
                
                print(f"   âœ… [{i}/{len(clips)}] {filename} ìƒì„± ì™„ë£Œ ({clip['duration']:.1f}ì´ˆ)")
                
            except subprocess.CalledProcessError as e:
                print(f"   âŒ [{i}/{len(clips)}] {filename} ìƒì„± ì‹¤íŒ¨")
                print(f"      ì—ëŸ¬: {e.stderr}")
        
        return shorts
    
    def create_fcpxml(self, shorts, filename="project.fcpxml"):
        """Final Cut Pro í”„ë¡œì íŠ¸ íŒŒì¼ ìƒì„±"""
        if not shorts:
            return None
        
        print(f"\nğŸ“¦ Final Cut Pro í”„ë¡œì íŠ¸ ìƒì„± ì¤‘...")
        
        fcpxml_path = os.path.join(self.output_dir, filename)
        
        # FCPXML ê¸°ë³¸ êµ¬ì¡°
        fcpxml = ET.Element('fcpxml', version='1.9')
        resources = ET.SubElement(fcpxml, 'resources')
        library = ET.SubElement(fcpxml, 'library')
        event = ET.SubElement(library, 'event', name='í™”ì œë³„ ìˆí¼')
        project = ET.SubElement(event, 'project', name='ìˆí¼ í”„ë¡œì íŠ¸')
        sequence = ET.SubElement(project, 'sequence', format='r1', duration=f'{sum(s["duration"] for s in shorts):.2f}s')
        spine = ET.SubElement(sequence, 'spine')
        
        # ê° ìˆí¼ì„ íƒ€ì„ë¼ì¸ì— ì¶”ê°€
        for i, short in enumerate(shorts):
            # ë¦¬ì†ŒìŠ¤ ë“±ë¡
            asset_id = f'r{i+1}'
            ET.SubElement(resources, 'asset', {
                'id': asset_id,
                'name': short['filename'],
                'src': f"file://{os.path.abspath(short['path'])}"
            })
            
            # í´ë¦½ ì¶”ê°€
            clip = ET.SubElement(spine, 'clip', {
                'name': short['filename'],
                'ref': asset_id,
                'duration': f'{short["duration"]:.2f}s',
                'start': f'{short["start"]:.2f}s'
            })
            
            # í‚¤ì›Œë“œ ë§ˆì»¤ ì¶”ê°€
            keywords_to_mark = short.get('keywords', [])
            if keywords_to_mark:
                keyword_text = ', '.join(keywords_to_mark)
                marker = ET.SubElement(clip, 'marker', {
                    'start': '0s',
                    'duration': '1/30s',
                    'value': keyword_text
                })
        
        xml_str = minidom.parseString(ET.tostring(fcpxml)).toprettyxml(indent="  ")
        
        with open(fcpxml_path, 'w', encoding='utf-8') as f:
            f.write(xml_str)
        
        print(f"âœ… FCPXML ìƒì„± ì™„ë£Œ: {fcpxml_path}")
        return fcpxml_path
    
    def save_report(self, shorts, filename="report.txt"):
        """ê²°ê³¼ ë¦¬í¬íŠ¸ ì €ì¥"""
        report_path = os.path.join(self.output_dir, filename)
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("=" * 60 + "\n")
            f.write("í™”ì œë³„ ìˆí¼ ìƒì„± ë¦¬í¬íŠ¸ (ì „ì²´ í™”ì œ)\n")
            f.write("=" * 60 + "\n\n")
            f.write(f"ì›ë³¸ ì˜ìƒ: {self.video_path}\n")
            f.write(f"ìƒì„±ëœ ìˆí¼: {len(shorts)}ê°œ\n")
            f.write(f"ìœ ì‚¬ë„ ì„ê³„ê°’: {self.similarity_threshold}\n")
            f.write(f"í•„í„°ë§ í‚¤ì›Œë“œ: ì—†ìŒ (ì „ì²´ í™”ì œ ì¶”ì¶œ)\n\n")
            
            for i, short in enumerate(shorts, 1):
                f.write(f"\n[{i}] {short['filename']}\n")
                if short.get('keywords'):
                    f.write(f"    ìë™ í‚¤ì›Œë“œ: {', '.join(short['keywords'])}\n")
                f.write(f"    ì‹œê°„: {self._format_time(short['start'])} ~ {self._format_time(short['end'])}\n")
                f.write(f"    ê¸¸ì´: {short['duration']:.1f}ì´ˆ\n")
                f.write(f"    ë‚´ìš©: {short['text'][:100]}{'...' if len(short['text']) > 100 else ''}\n")
                f.write("-" * 60 + "\n")
        
        print(f"ğŸ“„ ë¦¬í¬íŠ¸ ì €ì¥: {report_path}")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    # Segmentation fault ë°©ì§€
    os.environ["OMP_NUM_THREADS"] = "1"
    os.environ["MKL_NUM_THREADS"] = "1"
    
    try:
        torch.set_num_threads(1)
    except ImportError:
        pass
    
    # ==================== ì„¤ì • ====================
    VIDEO_PATH = "2025-10-29 ë¨¹ë°©_music_removed.mp4"  # ì˜ìƒ íŒŒì¼ ê²½ë¡œ
    OUTPUT_DIR = "fast_shorts"      # ì¶œë ¥ í´ë”
    
    # í™”ì œ ê°ì§€ ì„¤ì •
    SIMILARITY_THRESHOLD = 0.5  # ë‚®ì„ìˆ˜ë¡ ë” ë§ì€ í™”ì œë¡œ ë¶„í•  (0.5~0.8 ê¶Œì¥)
    
    # ìˆí¼ ê¸¸ì´ ì„¤ì •
    MIN_DURATION = 15  # ìµœì†Œ ê¸¸ì´ (ì´ˆ)
    MAX_DURATION = 60  # ìµœëŒ€ ê¸¸ì´ (ì´ˆ)
    
    # ì„¸ë¡œ ì˜ìƒ ì—¬ë¶€
    VERTICAL = True  # True: 9:16 ì„¸ë¡œ, False: 16:9 ê°€ë¡œ
    # =============================================
    
    # ffmpeg ì„¤ì¹˜ í™•ì¸
    try:
        subprocess.run(['ffmpeg', '-version'], 
                      capture_output=True, check=True)
    except (subprocess.CalledProcessError, FileNotFoundError):
        print("âŒ ffmpegê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤!")
        print("\nì„¤ì¹˜ ë°©ë²•:")
        print("  Mac: brew install ffmpeg")
        print("  Windows: https://ffmpeg.org/download.html")
        return
    
    if not os.path.exists(VIDEO_PATH):
        print(f"âŒ ì˜ìƒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {VIDEO_PATH}")
        return
    
    print("ğŸ¬ í™”ì œ ì „í™˜ ê¸°ë°˜ ìˆí¼ ìë™ ìƒì„±ê¸°")
    print("=" * 60)
    print("ğŸ’¡ í‚¤ì›Œë“œ í•„í„°ë§ ì—†ì´ ëª¨ë“  í™”ì œ êµ¬ê°„ì„ ìˆí¼ìœ¼ë¡œ ì œì‘í•©ë‹ˆë‹¤")
    print("=" * 60)
    
    creator = TopicBasedShortCreator(
        VIDEO_PATH,
        output_dir=OUTPUT_DIR,
        similarity_threshold=SIMILARITY_THRESHOLD
    )
    
    # 1. ìŒì„± ì¸ì‹
    transcription = creator.transcribe_video()
    
    # 2. í™”ì œë³„ êµ¬ê°„ ì°¾ê¸° (í‚¤ì›Œë“œ í•„í„°ë§ ì—†ìŒ)
    topic_clips = creator.find_topic_segments(
        transcription,
        min_duration=MIN_DURATION,
        max_duration=MAX_DURATION
    )
    
    if not topic_clips:
        print("\nâŒ ì¡°ê±´ì— ë§ëŠ” êµ¬ê°„ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        print(f"ğŸ’¡ íŒ: SIMILARITY_THRESHOLDë¥¼ ì¡°ì •í•˜ê±°ë‚˜ MIN_DURATIONì„ ë‚®ì¶°ë³´ì„¸ìš”")
        return
    
    # 3. ìˆí¼ ìƒì„±
    shorts = creator.create_shorts(topic_clips, vertical=VERTICAL)
    
    if not shorts:
        print("\nâŒ ìˆí¼ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return
    
    # 4. FCP í”„ë¡œì íŠ¸ ìƒì„±
    fcpxml_path = creator.create_fcpxml(shorts)
    
    # 5. ë¦¬í¬íŠ¸ ì €ì¥
    creator.save_report(shorts)
    
    # ì™„ë£Œ!
    print("\n" + "=" * 60)
    print("ğŸ‰ ì™„ë£Œ!")
    print("=" * 60)
    print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {os.path.abspath(OUTPUT_DIR)}")
    print(f"ğŸ“Š ìƒì„±ëœ ìˆí¼: {len(shorts)}ê°œ")
    print(f"\nğŸ’¡ ì„¤ì •:")
    print(f"   - í™”ì œ ì „í™˜ ì„ê³„ê°’: {SIMILARITY_THRESHOLD}")
    print(f"   - í‚¤ì›Œë“œ í•„í„°ë§: OFF (ëª¨ë“  í™”ì œ í¬í•¨)")
    print(f"   - ìµœì†Œ ê¸¸ì´: {MIN_DURATION}ì´ˆ")
    print(f"   - ìµœëŒ€ ê¸¸ì´: {MAX_DURATION}ì´ˆ")
    print(f"\nìƒì„±ëœ íŒŒì¼:")
    for i, short in enumerate(shorts[:10], 1):
        keywords = short.get('keywords', [])
        keyword_text = f" | í‚¤ì›Œë“œ: {', '.join(keywords)}" if keywords else ""
        print(f"  {short['filename']} ({short['duration']:.1f}ì´ˆ){keyword_text}")
    if len(shorts) > 10:
        print(f"  ... ì™¸ {len(shorts)-10}ê°œ")
    print(f"\nğŸ¬ {fcpxml_path}ì„ Final Cut Proì—ì„œ ì—´ì–´ë³´ì„¸ìš”!")
    print("=" * 60)


if __name__ == "__main__":
    try:
        from faster_whisper import WhisperModel
        from sentence_transformers import SentenceTransformer
    except ImportError:
        print("âŒ í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•´ì£¼ì„¸ìš”:")
        print("\npip install faster-whisper sentence-transformers")
        print("\nğŸ’¡ faster-whisperëŠ” ê¸°ì¡´ Whisperë³´ë‹¤ 4-5ë°° ë¹ ë¦…ë‹ˆë‹¤!")
        exit(1)
    main()